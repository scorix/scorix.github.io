这个话题始于 ruby 里的 `Hash#rehash`

## rehash

说起 `rehash` 方法，它究竟是做什么用的呢？我们先来试验一下。

### rehash_array_key

```
# rehash_array_key.rb
def display_nil(obj)
  obj.nil? ? 'nil' : obj.inspect
end

a = []; hash = {a => a}
puts "before change:\n  a = #{a}\n  hash = #{hash}\n  hash[a] = #{display_nil(hash[a])}\n"

a << :foo
puts "after change, before rehash:\n  a = #{a}\n  hash = #{hash}\n  hash[a] = #{display_nil(hash[a])}\n"

hash.rehash
puts "after rehash:\n  a = #{a}\n  hash = #{hash}\n  hash[a] = #{display_nil(hash[a])}\n"
```

结果是这样的：

```
before change:
  a = []
  hash = {[]=>[]}
  hash[a] = []
after change, before rehash:
  a = [:foo]
  hash = {[:foo]=>[:foo]}
  hash[a] = nil
after rehash:
  a = [:foo]
  hash = {[:foo]=>[:foo]}
  hash[a] = [:foo]
```

我们发现，当数组 a 发生变化的时候，如果不 rehash，那么 hash[a] 就会取不到值。

那么，key 换成别的类型是不是也是这样呢？我们来试一试 hash 和 自定义类。

### rehash_hash_key

```
def display_nil(obj)
  obj.nil? ? 'nil' : obj.inspect
end

a = {}; hash = {a => a}
puts "before change:\n  a = #{a}\n  hash = #{hash}\n  hash[a] = #{display_nil(hash[a])}\n"

a[:foo] = :bar
puts "after change, before rehash:\n  a = #{a}\n  hash = #{hash}\n  hash[a] = #{display_nil(hash[a])}\n"

hash.rehash
puts "after rehash:\n  a = #{a}\n  hash = #{hash}\n  hash[a] = #{display_nil(hash[a])}\n"
```

Result

```
before change:
  a = {}
  hash = {{}=>{}}
  hash[a] = {}
after change, before rehash:
  a = {:foo=>:bar}
  hash = {{:foo=>:bar}=>{:foo=>:bar}}
  hash[a] = nil
after rehash:
  a = {:foo=>:bar}
  hash = {{:foo=>:bar}=>{:foo=>:bar}}
  hash[a] = {:foo=>:bar}
```

### rehash_object_key

```
def display_nil(obj)
  obj.nil? ? 'nil' : obj.inspect
end


class A
  attr_accessor :foo
end
a = A.new; hash = {a => a}

puts "before change:\n  a = #{a}\n  hash = #{hash}\n  hash[a] = #{display_nil(hash[a])}\n"

a.foo = :bar
puts "after change, before rehash:\n  a = #{a}\n  hash = #{hash}\n  hash[a] = #{display_nil(hash[a])}\n"

hash.rehash
puts "after rehash:\n  a = #{a}\n  hash = #{hash}\n  hash[a] = #{display_nil(hash[a])}\n"
```

Result

```
before change:
  a = #<A:0x007fe22308ab30>
  hash = {#<A:0x007fe22308ab30>=>#<A:0x007fe22308ab30>}
  hash[a] = #<A:0x007fe22308ab30>
after change, before rehash:
  a = #<A:0x007fe22308ab30>
  hash = {#<A:0x007fe22308ab30 @foo=:bar>=>#<A:0x007fe22308ab30 @foo=:bar>}
  hash[a] = #<A:0x007fe22308ab30 @foo=:bar>
after rehash:
  a = #<A:0x007fe22308ab30>
  hash = {#<A:0x007fe22308ab30 @foo=:bar>=>#<A:0x007fe22308ab30 @foo=:bar>}
  hash[a] = #<A:0x007fe22308ab30 @foo=:bar>
```

## 结论

试验里我们看出，rehash 实际上是在 key 发生变化以后 reindex 了 hash。

并不是所有时候都需要 rehash，最好的方式是写好测试，不过在不确定的情况下还是 rehash 一下比较保险。于是产生了一个新的疑问，rehash 的效率如何？

## benchmark `rehash`

由于 rehash 的本质是 reindex，那么它的效率跟 key 的数量一定是有关的，所以我们要对不同数量的 key 进行 benchmark。

### rehash 1 key

```
Benchmark.ips do |x|
  x.report('hash') { {a: 1} }
  x.report('rehash') { {a: 1}.rehash }
  x.compare!
end
```

这里我使用了 `benchmark-ips` 这个 gem，并省去了 require 的过程，如果你想自己试验一下的话，不要忘记 require 哦。

Result

```
Calculating -------------------------------------
                hash    55.574k i/100ms
              rehash    31.559k i/100ms
-------------------------------------------------
                hash      1.365M (±11.3%) i/s -      6.724M
              rehash    800.968k (±11.5%) i/s -      3.945M

Comparison:
                hash:  1365188.3 i/s
              rehash:   800968.1 i/s - 1.70x slower
```

### 3 keys

```
Benchmark.ips do |x|
  x.report('hash') { {a: 1, b: 2, c: 3} }
  x.report('rehash') { {a: 1, b: 2, c: 3}.rehash }
  x.compare!
end
```

Result

```
Calculating -------------------------------------
                hash    56.216k i/100ms
              rehash    36.886k i/100ms
-------------------------------------------------
                hash      1.103M (±15.8%) i/s -      5.397M
              rehash    711.616k (±11.4%) i/s -      3.504M

Comparison:
                hash:  1102728.4 i/s
              rehash:   711616.0 i/s - 1.55x slower
```

### 10 keys

```
Benchmark.ips do |x|
  x.report('hash') { {a: 1, b: 2, c: 3, d: 4, e: 5, f: 6, g: 7, h: 8, i: 9, j: 10} }
  x.report('rehash') { {a: 1, b: 2, c: 3, d: 4, e: 5, f: 6, g: 7, h: 8, i: 9, j: 10}.rehash }
  x.compare!
end
```

Result

```
Calculating -------------------------------------
                hash    20.695k i/100ms
              rehash    12.857k i/100ms
-------------------------------------------------
                hash    281.192k (±12.1%) i/s -      1.387M
              rehash    157.420k (±10.0%) i/s -    784.277k

Comparison:
                hash:   281191.7 i/s
              rehash:   157420.4 i/s - 1.79x slower
```

## 结论

首先，rehash 有一定的性能损耗，这是肯定的，比普通生成一个 hash 慢 50% - 80%。

等等！你们有没有发现什么？！我觉得我们需要再做一个试验。

# Benchmark hash

## keys

```
Benchmark.ips do |x|
  x.report('1') { {a: 1} }
  x.report('2') { {a: 1, b: 2} }
  x.report('3') { {a: 1, b: 2, c: 3} }
  x.report('4') { {a: 1, b: 2, c: 3, d: 4} }
  x.report('5') { {a: 1, b: 2, c: 3, d: 4, e: 5} }
  x.report('6') { {a: 1, b: 2, c: 3, d: 4, e: 5, f: 6} }
  x.report('7') { {a: 1, b: 2, c: 3, d: 4, e: 5, f: 6, g: 7} }
  x.report('8') { {a: 1, b: 2, c: 3, d: 4, e: 5, f: 6, g: 7, h: 8} }
  x.report('9') { {a: 1, b: 2, c: 3, d: 4, e: 5, f: 6, g: 7, h: 8, i: 9} }
  x.report('10') { {a: 1, b: 2, c: 3, d: 4, e: 5, f: 6, g: 7, h: 8, i: 9, j: 10} }
  x.report('11') { {a: 0, b: 1, c: 2, d: 3, e: 4, f: 5, g: 6, h: 7, i: 8, j: 9, k: 10} }
  x.report('12') { {a: 0, b: 1, c: 2, d: 3, e: 4, f: 5, g: 6, h: 7, i: 8, j: 9, k: 10, l: 11} }
  x.report('13') { {a: 0, b: 1, c: 2, d: 3, e: 4, f: 5, g: 6, h: 7, i: 8, j: 9, k: 10, l: 11, m: 12} }
  x.report('14') { {a: 0, b: 1, c: 2, d: 3, e: 4, f: 5, g: 6, h: 7, i: 8, j: 9, k: 10, l: 11, m: 12, n: 13} }
  x.compare!
end
```

Result

```
Calculating -------------------------------------
                   1    59.274k i/100ms
                   2    59.197k i/100ms
                   3    57.534k i/100ms
                   4    56.315k i/100ms
                   5    53.287k i/100ms
                   6    53.279k i/100ms
                   7    27.615k i/100ms
                   8    25.682k i/100ms
                   9    24.151k i/100ms
                  10    22.550k i/100ms
                  11    21.215k i/100ms
                  12    19.955k i/100ms
                  13    19.253k i/100ms
                  14    18.257k i/100ms
-------------------------------------------------
                   1      1.466M (± 7.4%) i/s -      7.291M
                   2      1.364M (± 8.7%) i/s -      6.808M
                   3      1.297M (± 6.8%) i/s -      6.501M
                   4      1.229M (± 6.3%) i/s -      6.138M
                   5      1.191M (± 7.0%) i/s -      5.968M
                   6      1.108M (± 7.4%) i/s -      5.541M
                   7    387.699k (± 5.8%) i/s -      1.933M
                   8    353.347k (± 8.1%) i/s -      1.772M
                   9    320.113k (± 6.8%) i/s -      1.594M
                  10    301.599k (±10.5%) i/s -      1.511M
                  11    279.825k (±10.4%) i/s -      1.400M
                  12    258.555k (±12.0%) i/s -      1.297M
                  13    243.653k (±11.9%) i/s -      1.213M
                  14    233.844k (±11.8%) i/s -      1.168M

Comparison:
                   1:  1465513.3 i/s
                   2:  1363906.5 i/s - 1.07x slower
                   3:  1296719.2 i/s - 1.13x slower
                   4:  1229084.3 i/s - 1.19x slower
                   5:  1190837.9 i/s - 1.23x slower
                   6:  1108225.9 i/s - 1.32x slower
                   7:   387699.0 i/s - 3.78x slower
                   8:   353347.4 i/s - 4.15x slower
                   9:   320112.9 i/s - 4.58x slower
                  10:   301599.1 i/s - 4.86x slower
                  11:   279825.2 i/s - 5.24x slower
                  12:   258555.5 i/s - 5.67x slower
                  13:   243653.3 i/s - 6.01x slower
                  14:   233843.8 i/s - 6.27x slower
```

结果令人震惊。当 key 的数量达到7的时候，居然比6个 key 的时候慢了1倍？！

原因我暂时不知道，我们继续别的试验。

## depth

```
Benchmark.ips do |x|
  x.report('1') { {a: 1} }
  x.report('2') { {a: {b: 2}} }
  x.report('3') { {a: {b: {c: 3}}} }
  x.report('4') { {a: {b: {c: {d: 4}}}} }
  x.report('5') { {a: {b: {c: {d: {e: 5}}}}} }
  x.report('6') { {a: {b: {c: {d: {e: {f: 6}}}}}} }
  x.report('7') { {a: {b: {c: {d: {e: {f: {g: 7}}}}}}} }
  x.report('8') { {a: {b: {c: {d: {e: {f: {g: {h: 8}}}}}}}} }
  x.report('9') { {a: {b: {c: {d: {e: {f: {g: {h: {i: 9}}}}}}}}} }
  x.report('10') { {a: {b: {c: {d: {e: {f: {g: {h: {i: {j: 10}}}}}}}}}} }
  x.compare!
end
```

Result

```
Calculating -------------------------------------
                   1    57.183k i/100ms
                   2    42.522k i/100ms
                   3    34.779k i/100ms
                   4    29.116k i/100ms
                   5    24.903k i/100ms
                   6    22.180k i/100ms
                   7    19.710k i/100ms
                   8    18.072k i/100ms
                   9    16.568k i/100ms
                  10    15.090k i/100ms
-------------------------------------------------
                   1      1.438M (± 7.1%) i/s -      7.205M
                   2    803.372k (± 6.3%) i/s -      4.040M
                   3    560.077k (± 6.1%) i/s -      2.817M
                   4    405.713k (±12.2%) i/s -      1.980M
                   5    328.887k (±10.4%) i/s -      1.644M
                   6    266.616k (±19.0%) i/s -      1.264M
                   7    241.454k (±11.9%) i/s -      1.202M
                   8    219.550k (± 7.9%) i/s -      1.102M
                   9    194.618k (± 8.6%) i/s -    977.512k
                  10    175.011k (±10.0%) i/s -    875.220k

Comparison:
                   1:  1437779.3 i/s
                   2:   803371.5 i/s - 1.79x slower
                   3:   560077.3 i/s - 2.57x slower
                   4:   405712.5 i/s - 3.54x slower
                   5:   328886.8 i/s - 4.37x slower
                   6:   266615.9 i/s - 5.39x slower
                   7:   241454.4 i/s - 5.95x slower
                   8:   219550.1 i/s - 6.55x slower
                   9:   194617.7 i/s - 7.39x slower
                  10:   175011.0 i/s - 8.22x slower
```

看来深度对性能损耗也是比较明显的。

## 小结

初始化 hash 的时候，要避免 key 数量过多，也要注意避免层级过深。

# 总结

频繁调用的代码里面，使用较少数量 key 的 hash 效率会比较高。

然而这里说的效率都是相对的，真正的瓶颈一般不在这里。不过实在找不到优化空间的话，本文也算提供了一点点思路。
